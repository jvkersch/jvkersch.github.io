[
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "posts/2024-11-18-recommendation-letters/index.html",
    "href": "posts/2024-11-18-recommendation-letters/index.html",
    "title": "On recommendation letters",
    "section": "",
    "text": "Every year I receive many requests from students for a letter of recommendation. I take this part of my academic responsibilities very seriously, since I know that a good-quality letter can make or break your application. Writing a letter takes me a long time (at least a day, spread out over several (re)writing sessions): unlike John Nash’s advisor, I typically write one or two pages, detailing your academic achievements but also our interactions over the years. To facilitate this process, I have listed a few things to look out for when you ask me for a letter of recommendation."
  },
  {
    "objectID": "posts/2024-11-18-recommendation-letters/index.html#who-should-ask-for-a-letter",
    "href": "posts/2024-11-18-recommendation-letters/index.html#who-should-ask-for-a-letter",
    "title": "On recommendation letters",
    "section": "Who should ask for a letter?",
    "text": "Who should ask for a letter?\nThe easiest scenario is the one where we have worked together closely, through your bachelor project or via an internship. In this case, the letter practically writes itself and it is more a question of what to leave out. This is also the case if we have built up a good working relation over the years, through interactions in various courses or committees that involve students. Likewise, if you have worked closely with someone in RC4, I usually know enough about you. In all of these cases I can write a well-researched and motivated letter.\nIt is not a disaster if we have not interacted much but you achieved good to very good grades in RC4 courses. In that case, my letter will focus mostly on your scholarly achievements. It is a problem if you have neither a personal connection nor good grades: in this case it becomes very difficult to write more than a rote letter, and you should maybe rethink whether you want to go ahead with me as your letter writer.\nI need at least 4 weeks of notice to write a good letter."
  },
  {
    "objectID": "posts/2024-11-18-recommendation-letters/index.html#what-information-should-you-provide",
    "href": "posts/2024-11-18-recommendation-letters/index.html#what-information-should-you-provide",
    "title": "On recommendation letters",
    "section": "What information should you provide?",
    "text": "What information should you provide?\nRegardless of what category you are in, you should provide me with some information about where you are applying:\n\nName of the college that you are applying to, and (if applicable) the research group.\nDeadline to submit the letter of recommendation.\n(Optionally) Guidelines provided by the college about what information the letter should contain. See here for an example (under “Tips for Letters of Recommendation”).\n\nEither directly or indirectly, universities will typically want to know the following:\n\nHow long I’ve known you, and in what capacity? This could be through coursework, but also because you did an RC4 internship, were a tutor, or just because we’ve talked in the corridors.\nHow many students are at your level? I can usually get this info from your transcripts, but let me know if anything stands out.\nWhat is your ability for planning and doing research? What demonstrable experience do you have in research? If you have done any internships at GUGC, have participated in the IGC research symposium, or anything similar, this is worth mentioning.\n\nYou should also tell me why you are applying, and why you think you’d make for a good fit. Please provide the following:\n\nYour motivation for applying at the given college.\nYour academic CV.\nTranscripts from your years at GUGC.\n\nLastly, if you feel comfortable sharing this information, please let know who else is providing a letter of recommendation for you. I will not discuss the contents of my letter with them, but it helps to know what aspects of your CV I should emphasize and which ones will probably be repetitive.\nYou may not have all of these materials available right away. If so, just indicate when you will be able to deliver them. If you are applying to multiple colleges/research groups, please provide the information for each college/group separately.\nLastly, don’t be shy about mentioning anything else that you think is relevant, even if it is not strictly academic in nature. If I think it fits with the theme letter I will incorporate it, and if not I will just overlook it."
  },
  {
    "objectID": "posts/2024-11-18-recommendation-letters/index.html#things-that-you-should-keep-in-mind",
    "href": "posts/2024-11-18-recommendation-letters/index.html#things-that-you-should-keep-in-mind",
    "title": "On recommendation letters",
    "section": "Things that you should keep in mind",
    "text": "Things that you should keep in mind\n\nI need at least 4 weeks of notice to write a good letter.\nI will send the letter directly to the admissions office. I will not give you access to the content of the letter. If you need an “open” letter to add to your application package, please let me know and I will draft a short letter commenting on your general standing as a student.\nI don’t use generative AI to write recommendation letters."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Joris Vankerschaver",
    "section": "",
    "text": "I am a professor of statistics at Ghent University Global Campus in South Korea, where my research focuses on deep learning, statistics, and scientific computing, particularly their applications in biotech and life sciences.\nBefore joining GUGC, I worked for 8 years as a scientific software developer and consulting manager at Enthought Ltd, a digital transformation company based in Cambridge, UK. In this role, I wrote a bunch of code and advised companies in the life sciences sector on digital transformation and the effective use of AI in their operations.\nI obtained my PhD from the now defunct Department of Mathematical Physics and Astronomy at Ghent University in 2007. I was a Fulbright postdoc at Caltech (2007-09), a teaching visitor at UC San Diego (2010-12), and a research associate at Imperial College, London (2012-13).\n\nResearch\nOver the years, my interests have gradually shifted from applied differential geometry and mathematics physics, first to control theory and numerical integration, and most recently to statistical analysis and scientific computing.\n\nMy publication record is on Google Scholar\nCode artifacts find their way to my GitHub account\n\n\n\nTeaching\n\nIntroduction to Engineering Mathematics\nProbability and Statistics\n\nShiny apps\n\nIntroduction to Statistical Modeling\n\nCourse notes\nCourse slides\nShiny apps\n\n\n\n\nMiscellaneous\n\nOn recommendation letters (For students). Please read this if you want me to write an effective letter of recommendation.\n\n\n\nContact\nGhent University Global Campus\n119-5, Songdomunhwa-ro, Yeonsu-gu, Incheon 21985, Republic of Korea\n인천광역시 연수구 송도문화로 119-5 겐트대학교 글로벌캠퍼스, 21985"
  },
  {
    "objectID": "posts/2022-10-01-schwefel/index.html",
    "href": "posts/2022-10-01-schwefel/index.html",
    "title": "The Schwefel function",
    "section": "",
    "text": "Many optimization algorithms, especially in differential evolution and swarm intelligence, test their performance on a bunch of standard objective functions. Most of these functions are either straightforward (such as the spherical function, which is just the distance to the origin) or very well known (such as the Rastrigin function, which has its own Wikipedia page).\nOne function that stands out as being both somewhat mysterious and not easy to reason about right away is the Schwefel function. The form that is usually described in the literature has these weird constants in it, and the location of the global minimum likewise is also given numerically as \\(x_1 = \\cdots = x_n = 420.9687\\)), to limited precision. This made me curious: what’s up with the Schwefel function? Where did it come from? Can we be more precise about the location of its minima?"
  },
  {
    "objectID": "posts/2022-10-01-schwefel/index.html#introduction",
    "href": "posts/2022-10-01-schwefel/index.html#introduction",
    "title": "The Schwefel function",
    "section": "",
    "text": "Many optimization algorithms, especially in differential evolution and swarm intelligence, test their performance on a bunch of standard objective functions. Most of these functions are either straightforward (such as the spherical function, which is just the distance to the origin) or very well known (such as the Rastrigin function, which has its own Wikipedia page).\nOne function that stands out as being both somewhat mysterious and not easy to reason about right away is the Schwefel function. The form that is usually described in the literature has these weird constants in it, and the location of the global minimum likewise is also given numerically as \\(x_1 = \\cdots = x_n = 420.9687\\)), to limited precision. This made me curious: what’s up with the Schwefel function? Where did it come from? Can we be more precise about the location of its minima?"
  },
  {
    "objectID": "posts/2022-10-01-schwefel/index.html#mathematical-description",
    "href": "posts/2022-10-01-schwefel/index.html#mathematical-description",
    "title": "The Schwefel function",
    "section": "Mathematical description",
    "text": "Mathematical description\nThe Schwefel function is given by \\[\n    F(x) = - \\sum_{i = 1}^N x_i \\sin \\sqrt{|x_i|}.\n\\] Some references add \\(418.9829N\\) to this expression, so that the global minimum has function value roughly equal to zero. I won’t do that, but I’ll just accept that the function changes with increasing \\(N\\).\nUsually, the Schwefel function is enclosed in a box centered on the origin, of 1000 units on each side, i.e. \\(-500 \\le x_i \\le 500\\) for all \\(i = 1, \\ldots, N\\). The function has many local minima, as well as one global minimum at \\(x_1 = \\cdots = x_n = 420.9687\\), near the boundary of the domain. This makes it an interesting function to test optimization algorithms on, as it is easy for an algorithm to (a) fail to explore regions near the boundary of the domain, or (b) get stuck in another local minimum.\nThe Schwefel appears first in a book by (who else) Schwefel from 1977 (see Schwefel 1977, problem 2.3 in A1.2) but this book is not often cited. In fact, Google Scholar gives me no citations until 1991, when the evolutionary computing community picked up on it (Mühlenbein, Schomisch, and Born 1991 is the first reference I could find). Nowadays, it is used without citation, which is somewhat regrettable since it is not a widely known function.\n\n\nCode\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport numpy as np\n\ndef schwefel(x, y):\n    return -x*np.sin(np.sqrt(np.abs(x))) - y*np.sin(np.sqrt(np.abs(y)))\n\nr = 500\nx = np.linspace(-r, r, 100)\ny = np.linspace(-r, r, 100)\nX, Y = np.meshgrid(x, y)\nZ = schwefel(X, Y)\n\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\nsurf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n                       linewidth=0, antialiased=False)\n\nplt.show()\n\n\n\n\n\nThe Schwefel function in 2D.\n\n\n\n\nI was interested in finding the exact coordinates of the global minimum, as well as the value of the objective function at that point. To get started, observe that \\(F(x)\\) is the sum of a bunch of univariate functions: \\[\n    F(x) = f(x_1) + \\cdots + f(x_n),\n\\] where \\(f(x) = -x \\sin\\sqrt{|x|}\\). Consequently, the gradient of \\(F\\) is given by \\[\n    \\nabla F = \\left[\n        \\begin{matrix}\n            f'(x_1) \\\\\n            \\vdots \\\\\n            f'(x_n)\n        \\end{matrix}\n    \\right],\n\\] where \\(f'(x)\\) is the derivative of \\(f(x)\\). If we want to find the points where \\(\\nabla F\\) vanishes, we therefore have to find the zeros of \\(f'(x)\\), and solving a one-dimensional equation (even if it is nonlinear) is of course much easier than solving a system of nonlinear equations."
  },
  {
    "objectID": "posts/2022-10-01-schwefel/index.html#finding-the-minima-of-fx",
    "href": "posts/2022-10-01-schwefel/index.html#finding-the-minima-of-fx",
    "title": "The Schwefel function",
    "section": "Finding the minima of \\(f(x)\\)",
    "text": "Finding the minima of \\(f(x)\\)\nTo find the zeros of \\(f'(x)\\), we may assume that \\(x &gt; 0\\) (the case \\(x &lt; 0\\) is similar), so that \\[\n    f'(x) = - \\sin\\sqrt{x} - \\frac{\\sqrt{x}}{2} \\cos \\sqrt{x} = 0.\n\\]\nThis equation can be rewritten as \\[\n    \\tan \\sqrt{x} + \\frac{\\sqrt{x}}{2} = 0,\n\\] or, by substituting \\(y = \\sqrt{x}\\), as \\[\n    -2\\tan y = y.\n\\] In other words, we are looking for the fixed points of the function \\(g(y) = - 2\\tan y\\). There are a few things to keep in mind, though.\nBy looking at the graph of \\(-2\\tan y\\), we see that there are many fixed points, and in particular, there is one inside each period of the tangent function. We can therefore parametrize these fixed points as \\(y = z + k \\pi\\), where \\(k\\) is an integer and \\(z \\in (-\\pi/2, \\pi/2)\\). It turns out it will be easier to fix \\(k\\), and look for \\(z\\) inside one fundamental period of the tangent, by solving \\[\n    \\tan z = - \\frac{z + k \\pi}{2}.\n\\]\nThis equation has a unique fixed point, but it is unstable (since \\(|g'(y)| &gt; 1\\)). To work around this, we take the arctan of both sides to get \\[\n    z = - \\arctan\\left( \\frac{z + k \\pi}{2} \\right).\n\\] This gives us a fixed-point equation with a unique fixed point that is stable (attracting), so we can solve this e.g. by fixed-point iteration. Once we have a solution \\(z = z_\\text{ext}\\), the corresponding \\(x\\) can then be done by putting \\[\n    x_\\text{ext} = (z_\\text{ext} + k \\pi)^2.\n\\] The fixed-point equation has a few interesting properties:\n\nFor \\(k &gt; 0\\), the solution \\(z_\\text{ext}\\) will be negative: \\(z_\\text{ext} \\in (-\\pi/2, 0)\\).\nAs \\(k\\) increases, \\(z_\\text{ext}\\) will tend towards \\(-\\pi/2\\).\n\nBoth of these properties follow from the graph of the arctan function shifted over \\(k \\pi\\) units to the left.\nFurthermore, by substituting the expression for the solution back into \\(f(x)\\) and using these sign properties, we get that \\[\n    f(x_\\text{ext}) = (-1)^k x_\\text{ext}\\sqrt{\\frac{x_\\text{ext}}{4 + x_\\text{ext}}}.\n\\] In other words, we get an alternating series of minima (for \\(k\\) odd) and maxima (for \\(k\\) even), whose magnitude increases with increasing \\(k\\).\nThe table below lists the first few zeros of \\(f'(x)\\), together with the value of \\(f(x)\\).\n\n\nCode\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\nfrom math import atan, pi\nfrom scipy.optimize import fixed_point\n\ndef schwefel_1d(x):\n    return -x*np.sin(np.abs(x)**0.5)\n\ndef solve_fixed_point(k):\n    def fpe(z):\n        return -atan((z + k*pi)/2)\n    z_optim = fixed_point(fpe, 0)[()]\n    x_optim = (z_optim + k*pi)**2\n    return x_optim, schwefel_1d(x_optim)\n\ntable = [(k,) + solve_fixed_point(k) for k in range(1, 8)]\nMarkdown(tabulate(\n    table, \n    headers=[\"Index\", \"x\", \"f(x)\"],\n    floatfmt=\".8f\"\n))\n\n\n\n\nTable 1: Extrema and function values for the 1D Schwefel function.\n\n\n\n\n\n\nIndex\nx\nf(x)\n\n\n\n\n1\n5.23919930\n-3.94530163\n\n\n2\n25.87741735\n24.08296022\n\n\n3\n65.54786509\n-63.63498195\n\n\n4\n124.82935642\n122.87617351\n\n\n5\n203.81425265\n-201.84321788\n\n\n6\n302.52493561\n300.54455266\n\n\n7\n420.96874636\n-418.98288727\n\n\n\n\n\n\n\n\n\n\nCode\nxs = np.linspace(0, 500, 500)\nys = schwefel_1d(xs)\n\nplt.plot(xs, ys)\nplt.plot([item[1] for item in table],\n         [item[2] for item in table],\n         \"ro\")\n\n\n\n\n\nExtrema of the 1D Schwefel function."
  },
  {
    "objectID": "posts/2022-10-01-schwefel/index.html#extrema-of-the-schwefel-function",
    "href": "posts/2022-10-01-schwefel/index.html#extrema-of-the-schwefel-function",
    "title": "The Schwefel function",
    "section": "Extrema of the Schwefel function",
    "text": "Extrema of the Schwefel function\nThis tells us everything we need to know about minima and maxima of \\(F\\). First of all, we can find all (coordinate-wise positive) extrema of \\(F(x)\\) by finding all of the zeros of the aforementioned fixed-point equation (see Table 1), and then choosing (with replacement) \\(n\\) of these zeros and assembling them into a coordinate vector. Each such \\(n\\)-vector is a zero of \\(\\nabla F\\). In 2D, this gives the distribution of extrema as shown below.\n\n\nCode\nr = 500\nx = np.linspace(-r, r, 100)\ny = np.linspace(-r, r, 100)\nX, Y = np.meshgrid(x, y)\nZ = schwefel(X, Y)\n    \nplt.figure(figsize=(7, 7))\nplt.contour(X, Y, Z, levels=20, cmap=cm.coolwarm)\n\nextrema = np.asarray([item[1] for item in table])\nXext, Yext = np.meshgrid(extrema, extrema)\n\ndef s(x, y):\n    plt.scatter(x, y, fc='gray', ec='black', zorder=2)\n\ns(Xext, Yext)\ns(Xext, -Yext)\ns(-Xext, Yext)\ns(-Xext, -Yext)\n\n\n\n\n\nExtrema of the 1D Schwefel function.\n\n\n\n\nThe remaining question is which of these extrema provides the global minimum. First of all, note that \\(F\\) being the sum of \\(n\\) copies of \\(f\\) tells us that the global minimum must have \\(x_1 = \\cdots = x_n = x_\\text{min}\\), with \\(x_\\text{min}\\) the global minimum of \\(f(x)\\). So we can reduce our \\(n\\)-dimensional minimization problem to a one-dimensional one, for which we have the fixed point equation.\nSecondly, where is \\(x_\\text{min}\\) located? For this, we use the expression for the minima and maxima derived earlier. We need to find the largest odd value for \\(k\\) such that \\(x_\\text{ext}\\) is still within our domain. Since our domain is limited by \\(x = 500\\), this gives us \\(k = 7\\).\nNow, we either solve the fixed-point equation for \\(k = 7\\), or we consult table Table 1. Either way, we get \\[\n    x_\\text{ext} = (z_\\text{ext} + 7 \\pi)^2 \\approx 420.96874635998194.\n\\] This is precisely the value quoted in various sources, to greater accuracy. This approximation is correct to about 8 decimal places (at least), corresponding to the default accuracy of SciPy’s fixed_point solver. A higher-accuracy approximation is given in the next section."
  },
  {
    "objectID": "posts/2022-10-01-schwefel/index.html#high-precision-location-of-the-extremum",
    "href": "posts/2022-10-01-schwefel/index.html#high-precision-location-of-the-extremum",
    "title": "The Schwefel function",
    "section": "High-precision location of the extremum",
    "text": "High-precision location of the extremum\nAdded 2024-01-03.\nUsing the mpmath library for arbitrary-precision floating point arithmetic, we can find the value for \\(x_\\text{ext}\\) to very high precision, in this case to approximately 50 decimal places. This value can be useful e.g. when calibrating your optimizer.\n\nfrom mpmath import mp\nmp.dps = 60\n\nz = mp.mpf(0)\nfor _ in range(50):\n    # each iteration gives us 2 decimal places, so a fixed \n    # number of 50 iterations should be more than enough.\n    z = -mp.atan((z + 7*mp.pi)/2)\n\nx = (z + 7*mp.pi)**2\nprint(f\"x = {x}\")\n\nx = 420.968746359982027311844365018686486001674755877017274182781\n\n\nWith this value for \\(x_\\text{ext}\\), \\(f'(x)\\) becomes vanishingly small, indicating that we’re indeed right at the extremum.\n\n\nCode\nimport mpmath\n\nresid = -mp.sin(x**0.5) - x**0.5/2 * mp.cos(x**0.5)\nprint(f\"f'(x) = {mpmath.nstr(resid)}\")\n\n\nf'(x) = -7.00089e-61"
  },
  {
    "objectID": "posts/2022-10-01-schwefel/index.html#approximate-locations-of-the-extrema",
    "href": "posts/2022-10-01-schwefel/index.html#approximate-locations-of-the-extrema",
    "title": "The Schwefel function",
    "section": "Approximate locations of the extrema",
    "text": "Approximate locations of the extrema\n(Schwefel 1977) has the following approximate expression for the extrema: \\[\n    x_\\text{ext} \\approx \\pm \\pi^2\\left(\\frac{1}{2} + k\\right)^2,\n\\] valid when \\(k\\) is large. This follows easily from the fixed-point equation: for \\(k\\) large, \\(\\arctan\\left( \\frac{z + k \\pi}{2} \\right)\\) tends to \\(-\\pi/2\\), so that \\(z_\\text{ext} \\approx \\pi/2\\), and the approximation for \\(x_\\text{ext}\\) follows."
  }
]